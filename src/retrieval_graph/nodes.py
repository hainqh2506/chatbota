
# file: nodes.py
import os
import logging
from dotenv import load_dotenv
from langgraph.prebuilt import create_react_agent
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
# Ch·ªçn LLM, v√≠ d·ª• Google Generative AI (Gemini)
from langchain_google_genai import ChatGoogleGenerativeAI
from configuration import VietnameseEmbeddings, load_gemini
# Import c√°c Pydantic model v√† AmelaReactCompatibleAgentState t·ª´ file state.py
from state import AmelaReactCompatibleAgentState, QueryAnalysisOutput
from typing import List, Dict, Any, Optional, Annotated
from langchain_tavily import TavilySearch
from langgraph.checkpoint.memory import InMemorySaver
tool = TavilySearch(max_results=2)
# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng (v√≠ d·ª• GOOGLE_API_KEY)
load_dotenv()

# --- C·∫•u h√¨nh Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Kh·ªüi t·∫°o LLM cho Query Analysis ---
# S·ª≠ d·ª•ng model t∆∞∆°ng t·ª± nh∆∞ trong ADK c·ªßa b·∫°n
# ƒê·∫£m b·∫£o GOOGLE_API_KEY ƒë√£ ƒë∆∞·ª£c set trong .env ho·∫∑c m√¥i tr∆∞·ªùng
try:
    qpa_llm = load_gemini()
    logger.info("Kh·ªüi t·∫°o LLM cho Query Analysis (gemini-2.0-flash-latest) th√†nh c√¥ng.")
except Exception as e:
    logger.error(f"L·ªói khi kh·ªüi t·∫°o LLM cho Query Analysis: {e}. Vui l√≤ng ki·ªÉm tra GOOGLE_API_KEY.")
    # C√≥ th·ªÉ raise l·ªói ho·∫∑c d√πng m·ªôt LLM d·ª± ph√≤ng n·∫øu mu·ªën
    raise

# --- Prompt cho Query Analysis Agent ---

query_analysis_prompt_template_str = """
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch v√† l·∫≠p k·∫ø ho·∫°ch cho tr·ª£ l√Ω ·∫£o Amela.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc v√† ph√¢n t√≠ch c√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng, x√°c ƒë·ªãnh c√°c ph·∫ßn (sub-questions), l√™n k·∫ø ho·∫°ch tr·∫£ l·ªùi, v√† t·ªëi ∆∞u h√≥a truy v·∫•n t√¨m ki·∫øm cho t·ª´ng ph·∫ßn.

**TH√îNG TIN ƒê·∫¶U V√ÄO:**
- C√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng: {original_query}
- Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng: {user_roles}
## Quan tr·ªçng: N·∫øu th√¥ng tin vai tr√≤ ng∆∞·ªùi d√πng ƒë∆∞·ª£c cung c·∫•p, h√£y s·ª≠ d·ª•ng n√≥. N·∫øu kh√¥ng c√≥, m·∫∑c ƒë·ªãnh l√† ["Employee"].

**QUY TR√åNH PH√ÇN T√çCH & L·∫¨P K·∫æ HO·∫†CH**
0. **Nh·∫≠n di·ªán lo·∫°i c√¢u h·ªèi:**
   - N·∫øu `original_user_query` l√† l·ªùi ch√†o h·ªèi ƒë∆°n thu·∫ßn (v√≠ d·ª•: "hi", "hello", "ch√†o b·∫°n"):
      - ƒê·∫∑t `intent` l√† "social_greeting".
      - `effective_search_query` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng ho·∫∑c ch√≠nh `original_user_query`.
      - `sub_questions`, `plan_steps` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt c√¢u ch√†o l·∫°i ph√π h·ª£p (v√≠ d·ª•: ["Ch√†o b·∫°n! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"]).
      - C√°c tr∆∞·ªùng kh√°c nh∆∞ `sub_questions`, `effective_search_query`, `clarifying_questions` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng ho·∫∑c null.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu `original_user_query` l√† c√¢u h·ªèi r·∫•t chung v·ªÅ b·∫£n th√¢n chatbot (v√≠ d·ª•: "b·∫°n l√† ai?", "b·∫°n l√†m g√¨?"):
      - ƒê·∫∑t `intent` l√† "chatbot_capability_query".
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt c√¢u gi·ªõi thi·ªáu ng·∫Øn v·ªÅ chatbot (v√≠ d·ª•: ["T√¥i l√† Amela, tr·ª£ l√Ω ·∫£o th√¥ng minh c·ªßa c√¥ng ty."]).
      - C√°c tr∆∞·ªùng kh√°c c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu `original_user_query` ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p, t·ª•c tƒ©u:
      - ƒê·∫∑t `intent` l√† "blocked_profanity".
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt th√¥ng b√°o t·ª´ ch·ªëi x·ª≠ l√Ω (v√≠ d·ª•: ["Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu n√†y."]).
      - C√°c tr∆∞·ªùng kh√°c c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu kh√¥ng, ti·∫øp t·ª•c c√°c b∆∞·ªõc ph√¢n t√≠ch s√¢u h∆°n.
1. **X√°c ƒë·ªãnh `asker_role_context`:** D·ª±a tr√™n `user_roles`, suy lu·∫≠n vai tr√≤ ch√≠nh c·ªßa ng∆∞·ªùi h·ªèi (v√≠ d·ª•: "nh√¢n vi√™n", "qu·∫£n l√Ω"). M·∫∑c ƒë·ªãnh "Employee".
2. **X√°c ƒë·ªãnh `intent`:** √ù ƒë·ªãnh c·ªët l√µi c·ªßa c√¢u h·ªèi.
3. **Tr√≠ch xu·∫•t `entities`:** Danh s√°ch c√°c t·ª´ kh√≥a, th·ª±c th·ªÉ quan tr·ªçng.
4. **T√°ch `sub_questions`:** Chia c√¢u h·ªèi g·ªëc th√†nh c√°c ph·∫ßn nh·ªè, m·ªói ph·∫ßn c√≥ `text`, `intent`, `entities`, v√† `dependencies` (li·ªát k√™ ch·ªâ s·ªë ph·ª• thu·ªôc v√†o c√°c sub-question kh√°c).
5. **L·∫≠p `plan_steps`:** Danh s√°ch c√°c b∆∞·ªõc c·∫ßn th·ª±c hi·ªán ƒë·ªÉ tr·∫£ l·ªùi t·ª´ng `sub_question` theo ƒë√∫ng th·ª© t·ª±.
6. **X√°c ƒë·ªãnh `clarifying_questions`:** Li·ªát k√™ nh·ªØng c√¢u h·ªèi ph·ª• c·∫ßn h·ªèi l·∫°i user n·∫øu c√≥ th√¥ng tin thi·∫øu r√µ r√†ng.
7. **∆Ø·ªõc t√≠nh `complexity_level`:** ƒê√°nh gi√° ƒë·ªô ph·ª©c t·∫°p t·ªïng th·ªÉ ("low", "medium", "high").
8. **T·∫°o `effective_search_query`:** Truy v·∫•n t√¨m ki·∫øm t·ªëi ∆∞u **d∆∞·ªõi d·∫°ng danh s√°ch**, t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng `sub_question`.

**Y√äU C·∫¶U OUTPUT (PH·∫¢I TR·∫¢ V·ªÄ JSON V√Ä TU√ÇN TH·ª¶ Pydantic Schema ƒë∆∞·ª£c cung c·∫•p)**
B·∫°n PH·∫¢I tr·∫£ v·ªÅ DUY NH·∫§T m·ªôt ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá, tu√¢n th·ªß ho√†n to√†n c·∫•u tr√∫c ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.
**TUY·ªÜT ƒê·ªêI KH√îNG bao g·ªìm c√°c d·∫•u ```json, ```, ho·∫∑c b·∫•t k·ª≥ vƒÉn b·∫£n n√†o kh√°c tr∆∞·ªõc ho·∫∑c sau ƒë·ªëi t∆∞·ª£ng JSON.**
V√≠ d·ª• v·ªÅ c·∫•u tr√∫c Pydantic schema m√† b·∫°n c·∫ßn tu√¢n theo:
```json
{{
  "original_query": "String",
  "user_roles": ["List[String]"],
  "asker_role_context": "String",
  "intent": "String",
  "entities": ["List[String]"],
  "sub_questions": [
    {{
      "text": "String",
      "intent": "String",
      "entities": ["List[String]"],
      "dependencies": ["List[Int]"]
    }}
  ],
  "plan_steps": ["List[String]"],
  "clarifying_questions": ["List[String]"],
  "complexity_level": "String or r·ªóng",
  "effective_search_query": ["List[String]"],
  "status": "String (lu√¥n l√† 'processed_for_main_agent')"
}}
```
**V√ç D·ª§ INPUT T·ª™ USER:**
{{"original_query": "l√†m th·∫ø n√†o ƒë·ªÉ ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi v√† th·ª±c hi·ªán quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n?", "user_roles": ["Developer"]}}

**V√ç D·ª§ OUTPUT JSON MONG MU·ªêN (ch·ªâ tr·∫£ v·ªÅ JSON object, kh√¥ng c√≥ markdown hay text kh√°c):**
```json
{{
  "original_query": "l√†m th·∫ø n√†o ƒë·ªÉ ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi v√† th·ª±c hi·ªán quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n?",
  "user_roles": ["Developer"],
  "asker_role_context": "nh√¢n vi√™n",
  "intent": "T√¨m hi·ªÉu quy tr√¨nh h√†nh ch√≠nh v·ªÅ b·∫£o hi·ªÉm x√£ h·ªôi v√† quy·∫øt to√°n thu·∫ø TNCN",
  "entities": ["b·∫£o hi·ªÉm x√£ h·ªôi", "quy·∫øt to√°n thu·∫ø TNCN"],
  "sub_questions": [
    {{
      "text": "c√°ch ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi?",
      "intent": "hi·ªÉu quy tr√¨nh ƒëƒÉng k√Ω BHXH",
      "entities": ["ƒëƒÉng k√Ω BHXH"],
      "dependencies": []
    }},
    {{
      "text": "l√†m th·∫ø n√†o ƒë·ªÉ th·ª±c hi·ªán quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n?",
      "intent": "hi·ªÉu quy tr√¨nh quy·∫øt to√°n thu·∫ø TNCN",
      "entities": ["quy·∫øt to√°n thu·∫ø TNCN"],
      "dependencies": [0]
    }}
  ],
  "plan_steps": [
    "T√°ch c√¢u h·ªèi th√†nh hai ph·∫ßn: BHXH v√† thu·∫ø TNCN",
    "T√¨m v√† t·ªïng h·ª£p h∆∞·ªõng d·∫´n ƒëƒÉng k√Ω BHXH t·ª´ t√†i li·ªáu n·ªôi b·ªô",
    "T√¨m v√† t·ªïng h·ª£p quy tr√¨nh quy·∫øt to√°n thu·∫ø TNCN",
    "Ki·ªÉm tra th√¥ng tin v√† k·∫øt h·ª£p k·∫øt qu·∫£",
    "Tr·∫£ l·ªùi l·∫ßn l∆∞·ª£t t·ª´ng ph·∫ßn tho·∫°i"
  ],
  "clarifying_questions": [],
  "complexity_level": "medium",
  "effective_search_query": [
    "h∆∞·ªõng d·∫´n ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi Amela",
    "quy tr√¨nh quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n Amela"
  ],
  "status": "processed_for_main_agent"
}}
```
"""

query_analysis_prompt = ChatPromptTemplate.from_template(query_analysis_prompt_template_str)

# K·∫øt h·ª£p LLM v·ªõi Pydantic Output Parser
# Langchain cho ph√©p LLM tr·∫£ v·ªÅ output d∆∞·ªõi d·∫°ng Pydantic model tr·ª±c ti·∫øp
# b·∫±ng c√°ch s·ª≠ d·ª•ng .with_structured_output()
structured_qpa_llm = qpa_llm.with_structured_output(QueryAnalysisOutput)

# Chain cho Query Analysis
query_analysis_chain = query_analysis_prompt | structured_qpa_llm

async def query_analysis_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    Node th·ª±c hi·ªán ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Query Analysis Node ---")
    original_query = state["original_query"]
    user_roles = state["user_roles"]
    # L·∫•y tin nh·∫Øn cu·ªëi c√πng t·ª´ user ƒë·ªÉ l√†m input cho QPA
    # Ho·∫∑c ƒë∆°n gi·∫£n l√† d√πng original_query n·∫øu ƒë√¢y l√† l∆∞·ª£t ƒë·∫ßu
    # Trong ADK, query ƒë∆∞·ª£c l·∫•y t·ª´ `new_message` ho·∫∑c `initial_pipeline_state["original_user_query"]`

    logger.info(f"Ph√¢n t√≠ch c√¢u h·ªèi: '{original_query}' v·ªõi vai tr√≤: {user_roles}")

    try:
        # G·ªçi chain ƒë·ªÉ l·∫•y k·∫øt qu·∫£ ph√¢n t√≠ch c√≥ c·∫•u tr√∫c
        analysis_result: QueryAnalysisOutput = await query_analysis_chain.ainvoke({
            "original_query": original_query,
            "user_roles": user_roles
        })
        logger.info(f"analyze_result l√†: {analysis_result}")
        logger.info(f"analyze_reult type l√†: {type(analysis_result)}")
        logger.info(f"K·∫øt qu·∫£ ph√¢n t√≠ch Query Analysis: {analysis_result.intent}")
        logger.debug(f"To√†n b·ªô k·∫øt qu·∫£ Query Analysis: {analysis_result.model_dump_json(indent=2)}")

        # C·∫≠p nh·∫≠t state v·ªõi k·∫øt qu·∫£ ph√¢n t√≠ch
        return {**state, "query_analysis": analysis_result} # Tr·∫£ v·ªÅ m·ªôt dict m·ªõi ƒë·ªÉ c·∫≠p nh·∫≠t state
    except Exception as e:
        logger.error(f"L·ªói trong Query Analysis Node: {e}", exc_info=True)
        # X·ª≠ l√Ω l·ªói, v√≠ d·ª•: tr·∫£ v·ªÅ m·ªôt QueryAnalysisOutput m·∫∑c ƒë·ªãnh ho·∫∑c ƒë·∫∑t m·ªôt c·ªù l·ªói trong state
        # T·∫°m th·ªùi, ch√∫ng ta s·∫Ω ƒë·ªÉ l·ªói n·ªïi l√™n ƒë·ªÉ debug
        # Ho·∫∑c c√≥ th·ªÉ t·∫°o m·ªôt QueryAnalysisOutput v·ªõi intent "error"
        error_analysis = QueryAnalysisOutput(
            original_query=original_query,
            user_roles=user_roles,
            asker_role_context="unknown",
            intent="query_analysis_error",
            entities=[],
            sub_questions=[],
            plan_steps=["C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ph√¢n t√≠ch c√¢u h·ªèi."],
            clarifying_questions=[],
            complexity_level="unknown",
            effective_search_query=[],
            status="error_in_qpa"
        )
        return {**state, "query_analysis": error_analysis}

# file: nodes.py (ti·∫øp t·ª•c t·ª´ file tr∆∞·ªõc)

# --- Constants cho Router ---
DIRECT_RESPONSE_INTENTS = ["social_greeting", "chatbot_capability_query", "blocked_profanity"]

async def route_after_qpa(state: AmelaReactCompatibleAgentState) -> str:
    """
    Quy·∫øt ƒë·ªãnh nh√°nh ti·∫øp theo sau khi Query Analysis ho√†n t·∫•t.
    Tr·∫£ v·ªÅ t√™n c·ªßa node ti·∫øp theo ho·∫∑c m·ªôt gi√° tr·ªã ƒë·∫∑c bi·ªát ƒë·ªÉ k·∫øt th√∫c s·ªõm.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Router Node (route_after_qpa) ---")
    query_analysis_result = state.get("query_analysis")

    if not query_analysis_result:
        logger.error("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ Query Analysis trong state. ƒê·ªãnh tuy·∫øn t·ªõi l·ªói.")
        return "error_handler" # Ho·∫∑c m·ªôt node x·ª≠ l√Ω l·ªói chung

    intent = query_analysis_result.intent
    clarifying_questions = query_analysis_result.clarifying_questions
    plan_steps = query_analysis_result.plan_steps

    logger.info(f"Router: Intent = {intent}, Clarifying Questions = {len(clarifying_questions) if clarifying_questions else 0}")

    # 1. X·ª≠ l√Ω c√°c intent c·∫ßn tr·∫£ l·ªùi tr·ª±c ti·∫øp
    if intent in DIRECT_RESPONSE_INTENTS:
        response_text = ""
        if plan_steps:
            response_text = " ".join(plan_steps)
        elif intent == "social_greeting":
            response_text = "Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o Amela, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. üòä"
        elif intent == "chatbot_capability_query":
            response_text = "T√¥i l√† Amber, tr·ª£ l√Ω ·∫£o Amela, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn nghi·ªáp v·ª• c·ªßa c√¥ng ty m√¨nh. üí°"
        elif intent == "blocked_profanity":
            response_text = "R·∫•t ti·∫øc, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n do ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p. üò•"
        else:
            response_text = "T√¥i ƒë√£ ghi nh·∫≠n y√™u c·∫ßu c·ªßa b·∫°n."

        if not response_text:
            response_text = "T√¥i ƒë√£ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."

        logger.info(f"Router: Intent '{intent}' y√™u c·∫ßu ph·∫£n h·ªìi tr·ª±c ti·∫øp. ƒê·ªãnh tuy·∫øn t·ªõi 'direct_response_node'.")
        # C·∫≠p nh·∫≠t state v·ªõi c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp ƒë·ªÉ node ti·∫øp theo c√≥ th·ªÉ d√πng
        # Quan tr·ªçng: LangGraph kh√¥ng cho ph√©p node router tr·ª±c ti·∫øp c·∫≠p nh·∫≠t state.
        # Ch√∫ng ta s·∫Ω t·∫°o m·ªôt node nh·ªè ƒë·ªÉ l√†m vi·ªác n√†y ho·∫∑c ƒë·ªÉ node cu·ªëi c√πng l√†m.
        # Hi·ªán t·∫°i, ch√∫ng ta s·∫Ω l∆∞u t·∫°m th√¥ng tin c·∫ßn thi·∫øt v√†o m·ªôt key n√†o ƒë√≥ n·∫øu c·∫ßn,
        # ho·∫∑c node `direct_response_node` s·∫Ω t·ª± t·∫°o response d·ª±a tr√™n intent.
        # ƒê·ªÉ ƒë∆°n gi·∫£n, node `direct_response_node` s·∫Ω t·ª± t·∫°o response d·ª±a v√†o intent t·ª´ `query_analysis`.
        return "direct_response_node"

    # 2. X·ª≠ l√Ω c√¢u h·ªèi l√†m r√µ
    if clarifying_questions:
        logger.info("Router: C·∫ßn l√†m r√µ th√¥ng tin. ƒê·ªãnh tuy·∫øn t·ªõi 'clarification_node'.")
        # `clarification_node` s·∫Ω s·ª≠ d·ª•ng `query_analysis.clarifying_questions` t·ª´ state
        return "clarification_node"

    # 3. N·∫øu kh√¥ng c√≥ tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát, chuy·ªÉn ƒë·∫øn agent ch√≠nh
    logger.info("Router: Kh√¥ng c·∫ßn ph·∫£n h·ªìi tr·ª±c ti·∫øp hay l√†m r√µ. ƒê·ªãnh tuy·∫øn t·ªõi 'main_assistant_node'.")
    return "main_assistant_node"
from langchain_core.messages import AIMessage
# --- Node cho Ph·∫£n h·ªìi tr·ª±c ti·∫øp ---
async def direct_response_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    T·∫°o ph·∫£n h·ªìi tr·ª±c ti·∫øp d·ª±a tr√™n intent t·ª´ QueryAnalysis.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Direct Response Node ---")
    query_analysis_result = state["query_analysis"]
    if not query_analysis_result: # Ki·ªÉm tra an to√†n
        final_answer = "ƒê√£ c√≥ l·ªói x·∫£y ra, kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi."
        logger.error("L·ªói trong direct_response_node: Kh√¥ng c√≥ query_analysis_result.")
    else:
        intent = query_analysis_result.intent
        plan_steps = query_analysis_result.plan_steps
        response_text = ""

        if plan_steps:
            response_text = " ".join(plan_steps)
        elif intent == "social_greeting":
            response_text = "Ch√†o b·∫°n! T√¥i l√† Amber tr·ª£ l√Ω ·∫£o Amela, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. üòä"
        elif intent == "chatbot_capability_query":
            response_text = "T√¥i l√† Amber, tr·ª£ l√Ω ·∫£o Amela, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn nghi·ªáp v·ª• c·ªßa c√¥ng ty m√¨nh. üí°"
        elif intent == "blocked_profanity":
            response_text = "R·∫•t ti·∫øc, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n do ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p. üò•"
        else:
            # Fallback n·∫øu c√≥ intent trong DIRECT_RESPONSE_INTENTS m√† kh√¥ng c√≥ plan_steps
            response_text = "T√¥i ƒë√£ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."

        final_answer = response_text
        logger.info(f"Direct Response Node: T·∫°o ph·∫£n h·ªìi: '{final_answer}'")
    return {
        "messages": [AIMessage(content=final_answer)], # LangGraph s·∫Ω t·ª± append v√†o state["messages"]
        "final_answer": final_answer, # V·∫´n c·∫≠p nh·∫≠t final_answer ƒë·ªÉ d·ªÖ truy c·∫≠p
        "clarification_needed": False
    }
        

# --- Node cho vi·ªác H·ªèi l·∫°i l√†m r√µ ---
async def clarification_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    T·∫°o c√¢u h·ªèi l√†m r√µ cho ng∆∞·ªùi d√πng.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Clarification Node ---")
    query_analysis_result = state["query_analysis"]
    if not query_analysis_result or not query_analysis_result.clarifying_questions:
        final_answer = "T√¥i c·∫ßn th√™m th√¥ng tin nh∆∞ng kh√¥ng r√µ c·∫ßn h·ªèi g√¨. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i kh√¥ng?"
        ask_clarification_questions = []
        logger.error("L·ªói trong clarification_node: Kh√¥ng c√≥ clarifying_questions.")
    else:
        clarifying_questions = query_analysis_result.clarifying_questions
        clarification_text = "ƒê·ªÉ c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n t·ªët nh·∫•t, vui l√≤ng l√†m r√µ th√™m c√°c ƒëi·ªÉm sau:\n"
        for i, q_text in enumerate(clarifying_questions):
            clarification_text += f"{i+1}. {q_text}\n"
        final_answer = clarification_text
        ask_clarification_questions = clarifying_questions
        logger.info(f"Clarification Node: T·∫°o c√¢u h·ªèi l√†m r√µ: '{final_answer}'")

    return {
        "messages": [AIMessage(content=final_answer)],
        "final_answer": final_answer,
        "clarification_needed": True,
        "ask_clarification_questions": ask_clarification_questions
    }

# file: nodes.py (ti·∫øp t·ª•c)
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage
from langchain.agents import create_tool_calling_agent # S·ª≠ d·ª•ng agent m·ªõi h∆°n
from langchain.agents import AgentExecutor
from langchain_core.prompts import MessagesPlaceholder # ƒê·ªÉ qu·∫£n l√Ω messages
from langchain_core.runnables.history import RunnableWithMessageHistory # N·∫øu d√πng memory

# Import tools t·ª´ file tools.py
from tools import main_assistant_tools # ƒê√¢y s·∫Ω l√† list c√°c tool objects

# --- Kh·ªüi t·∫°o LLM cho Main Assistant ---
try:
    # D√πng model m·∫°nh h∆°n m·ªôt ch√∫t cho agent ch√≠nh n·∫øu c·∫ßn
    main_llm = load_gemini()
    logger.info("Kh·ªüi t·∫°o LLM cho Main Assistant (gemini-2.0-flash-latest) th√†nh c√¥ng.")
except Exception as e:
    logger.error(f"L·ªói khi kh·ªüi t·∫°o LLM cho Main Assistant: {e}. Vui l√≤ng ki·ªÉm tra GOOGLE_API_KEY.")
    raise

# --- Prompt cho Main Assistant ---
# L·∫•y t·ª´ get_amela_agent_instruction_v1_structured_planner v√† ƒëi·ªÅu ch·ªânh
# Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng MessagesPlaceholder ƒë·ªÉ truy·ªÅn l·ªãch s·ª≠ h·ªôi tho·∫°i v√† input c·ªßa QPA
main_assistant_prompt_str_system = """
B·∫°n l√† Amber tr·ª£ l√Ω ·∫£o AI th√¢n thi·ªán, c√≥ t·ªï ch·ª©c v√† r·∫•t gi·ªèi trong vi·ªác th·ª±c hi·ªán k·∫ø ho·∫°ch ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi ph·ª©c t·∫°p cho nh√¢n vi√™n Amela.
B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c th√¥ng tin ph√¢n t√≠ch chi ti·∫øt t·ª´ Agent Ti·ªÅn x·ª≠ l√Ω (QueryAnalysisOutput) d∆∞·ªõi d·∫°ng m·ªôt tin nh·∫Øn h·ªá th·ªëng ho·∫∑c tin nh·∫Øn t·ª´ user ƒë·∫∑c bi·ªát.
H√£y s·ª≠ d·ª•ng th√¥ng tin ƒë√≥, bao g·ªìm `original_query`, `user_roles`, `asker_role_context`, `intent`, `sub_questions`, `plan_steps`, v√† `effective_search_query` ƒë·ªÉ th·ª±c hi·ªán.

**## TH√îNG TIN PH√ÇN T√çCH QUERY (T·ª´ Query Analysis Agent):**
{qpa_output_str}

**## VAI TR√í NG∆Ø·ªúI D√ôNG:**
{user_roles_str} (Vai tr√≤ suy lu·∫≠n: {asker_role_context})

**## K·∫æ HO·∫†CH H√ÄNH ƒê·ªòNG G·ª¢I √ù (T·ª´ Query Analysis Agent):**
{plan_steps_str}

**## QUY TR√åNH TH·ª∞C HI·ªÜN K·∫æ HO·∫†CH (B·∫ÆT BU·ªòC TU√ÇN TH·ª¶):**
D·ª±a v√†o th√¥ng tin ph√¢n t√≠ch ·ªü tr√™n, ƒë·∫∑c bi·ªát l√† `sub_questions` v√† `effective_search_query` t∆∞∆°ng ·ª©ng.
1.  **X·ª≠ l√Ω Tu·∫ßn t·ª± c√°c C√¢u h·ªèi Con (`sub_questions`)**:
    *   V·ªõi m·ªói sub-question, s·ª≠ d·ª•ng `effective_search_query` t∆∞∆°ng ·ª©ng ƒë·ªÉ ch·ªçn tool v√† t√¨m ki·∫øm.
    *   **Ch·ªçn Tool Ph√π h·ª£p:**
        *   ∆Øu ti√™n `company_structure_tool` n·∫øu sub-question li√™n quan ƒë·∫øn c∆° c·∫•u t·ªï ch·ª©c, ph√≤ng ban, ƒë·ªôi nh√≥m, t√™n vi·∫øt t·∫Øt.
        *   ∆Øu ti√™n `amela_documents_search_tool` cho c√°c c√¢u h·ªèi v·ªÅ quy tr√¨nh, ch√≠nh s√°ch, ki·∫øn th·ª©c n·ªôi b·ªô. Nh·ªõ r·∫±ng tool n√†y s·∫Ω t·ª± ƒë·ªông l·ªçc theo `user_roles`.
        *   D√πng `google_search_placeholder_tool` n·∫øu th√¥ng tin kh√¥ng c√≥ trong n·ªôi b·ªô v√† ph√π h·ª£p t√¨m ki·∫øm c√¥ng khai.
    *   **ƒê·ªçc k·ªπ k·∫øt qu·∫£ t·ª´ Tool:** T·ªïng h·ª£p th√¥ng tin li√™n quan nh·∫•t t·ª´ context ƒë·ªÉ x√¢y d·ª±ng c√¢u tr·∫£ l·ªùi m·∫°ch l·∫°c. **Kh√¥ng ch·ªâ li·ªát k√™ t√™n t√†i li·ªáu.**
    *   **L·ªçc Th√¥ng tin theo Vai tr√≤:** D·ª±a v√†o `asker_role_context`.

2.  **T·ªïng h·ª£p C√¢u Tr·∫£ l·ªùi Cu·ªëi c√πng:**
    *   K·∫øt h·ª£p c√°c c√¢u tr·∫£ l·ªùi cho t·ª´ng sub-question th√†nh m·ªôt c√¢u tr·∫£ l·ªùi t·ªïng th·ªÉ, m·∫°ch l·∫°c cho `original_query`.
    *   Gi·ªçng ƒëi·ªáu: Th√¢n thi·ªán, t√≠ch c·ª±c, nhi·ªát t√¨nh. D√πng ng√¥i "m√¨nh", g·ªçi ng∆∞·ªùi d√πng l√† "b·∫°n". C√≥ th·ªÉ d√πng emoji üòäüòâüöÄüí°.
    *   **Tr√≠ch d·∫´n ngu·ªìn (B·∫ÆT BU·ªòC):**
        *   T√†i li·ªáu n·ªôi b·ªô: Ghi r√µ `Source Name`. Ch√®n `Source URL` n·∫øu c√≥.
        *   Google: Ch√®n link Markdown.
        *   Li·ªát k√™ th√†nh danh s√°ch ƒë√°nh s·ªë sau c√¢u tr·∫£ l·ªùi.
    *   **X·ª≠ l√Ω khi kh√¥ng t√¨m th·∫•y th√¥ng tin:** N·∫øu tool kh√¥ng t√¨m th·∫•y g√¨, tr·∫£ l·ªùi duy√™n d√°ng: "·ªêi, Amber t√¨m k·ªπ r·ªìi m√† v·∫´n ch∆∞a th·∫•y th√¥ng tin b·∫°n c·∫ßn üò•..."

H√£y nh·ªõ, b·∫°n l√† Amber! B·∫Øt ƒë·∫ßu n√†o! üöÄ
"""

# Langchain agent th∆∞·ªùng d√πng MessagesPlaceholder. "chat_history" v√† "input" l√† keys ph·ªï bi·∫øn.
# "agent_scratchpad" ƒë∆∞·ª£c Langchain d√πng ƒë·ªÉ l∆∞u c√°c b∆∞·ªõc suy nghƒ© v√† tool call/response.
main_assistant_prompt = ChatPromptTemplate.from_messages([
    ("system", main_assistant_prompt_str_system),
    MessagesPlaceholder(variable_name="chat_history", optional=True), # L·ªãch s·ª≠ h·ªôi tho·∫°i
    ("human", "{input}"), # Input hi·ªán t·∫°i, s·∫Ω bao g·ªìm c·∫£ th√¥ng tin QPA
    MessagesPlaceholder(variable_name="agent_scratchpad"), # Cho tool calling
])
from langchain_core.messages.utils import trim_messages, count_tokens_approximately
# --- T·∫°o Langchain Agent ---
def simple_trimming_hook(state: Dict[str, Any]) -> Dict[str, Any]:
    current_messages = state.get("messages", [])
    trimmed = trim_messages(
        current_messages,
        max_tokens=1500, # Ng∆∞·ª°ng token, v√≠ d·ª•
        strategy="last",
        token_counter=count_tokens_approximately,
        include_system=True
    )
    return {"llm_input_messages": trimmed}
checkpointer = InMemorySaver()
react_agent_executor = create_react_agent(
    model=main_llm,
    tools=main_assistant_tools,
    pre_model_hook=simple_trimming_hook,
    checkpointer=checkpointer,
    verbose=True,
    state_schema=AmelaReactCompatibleAgentState,
    store=None
)

# S·ª≠ d·ª•ng create_tool_calling_agent l√† c√°ch hi·ªán ƒë·∫°i ƒë·ªÉ t·∫°o agent c√≥ kh·∫£ nƒÉng g·ªçi tool
main_agent_runnable = create_tool_calling_agent(
    llm=main_llm,
    tools=main_assistant_tools,
    prompt=main_assistant_prompt
)

# AgentExecutor s·∫Ω ch·∫°y agent v√† qu·∫£n l√Ω vi·ªác g·ªçi tool
# `handle_parsing_errors=True` gi√∫p agent ·ªïn ƒë·ªãnh h∆°n
main_agent_executor = AgentExecutor(
    agent=main_agent_runnable,
    tools=main_assistant_tools,
    verbose=True, # ƒê·ªÉ xem log chi ti·∫øt c·ªßa agent
    handle_parsing_errors=True,
    max_iterations=5 # Gi·ªõi h·∫°n s·ªë l·∫ßn g·ªçi tool ƒë·ªÉ tr√°nh v√≤ng l·∫∑p v√¥ h·∫°n
)


async def main_assistant_node(state: AmelaReactCompatibleAgentState) -> dict:
    """
    Node ch√≠nh th·ª±c thi k·∫ø ho·∫°ch t·ª´ QPA, s·ª≠ d·ª•ng tools ƒë·ªÉ tr·∫£ l·ªùi.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Main Assistant Node ---")
    query_analysis_result = state["query_analysis"]
    if not query_analysis_result:
        logger.error("Main Assistant Node: Kh√¥ng c√≥ Query Analysis result.")
        return {**state, "final_answer": "L·ªói: Kh√¥ng c√≥ th√¥ng tin ph√¢n t√≠ch ƒë·ªÉ x·ª≠ l√Ω.", "clarification_needed": False}

    # Chu·∫©n b·ªã input cho agent
    # Truy·ªÅn to√†n b·ªô QPA output nh∆∞ m·ªôt ph·∫ßn c·ªßa "input" cho agent n√†y.
    # Ho·∫∑c c√≥ th·ªÉ format n√≥ th√†nh m·ªôt tin nh·∫Øn h·ªá th·ªëng/user ƒë·∫∑c bi·ªát.
    # ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω format n√≥ v√†o prompt system v√† c√°c bi·∫øn kh√°c.
    qpa_output_str = query_analysis_result.model_dump_json(indent=2)
    user_roles_str = ", ".join(query_analysis_result.user_roles or ["Employee"])
    asker_role_context = query_analysis_result.asker_role_context or "Employee"
    plan_steps_str = "\n- ".join(query_analysis_result.plan_steps or ["Kh√¥ng c√≥ k·∫ø ho·∫°ch c·ª• th·ªÉ."])
    if query_analysis_result.plan_steps:
        plan_steps_str = "- " + plan_steps_str
    all_messages = state.get("messages", [])
    current_user_input_message = ""
    chat_history_for_agent = []
    if all_messages:
        if isinstance(all_messages[-1], HumanMessage):
            current_user_input_message = all_messages[-1].content
            chat_history_for_agent = all_messages[:-1]
        else: # Tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát, c√≥ th·ªÉ l√† l·ªói ho·∫∑c state kh·ªüi t·∫°o ch∆∞a ƒë√∫ng
            current_user_input_message = state["original_query"] # Fallback
            chat_history_for_agent = all_messages
    try:
        # G·ªçi agent executor
        # AgentExecutor mong ƒë·ª£i input l√† m·ªôt dict
        agent_input_dict = {
            "input": current_user_input_message, # Input cho HumanMessagePromptTemplate
            "chat_history": chat_history_for_agent, # Cho MessagesPlaceholder("chat_history")
            "qpa_output_str": qpa_output_str,
            "user_roles_str": user_roles_str,
            "asker_role_context": asker_role_context,
            "plan_steps_str": plan_steps_str,
        }

        response = await main_agent_executor.ainvoke(agent_input_dict)
        final_answer = response.get("output", "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ Amber.")

        if not final_answer: # Fallback
            final_answer = "Amber ch∆∞a th·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi l√∫c n√†y, b·∫°n th·ª≠ l·∫°i sau nh√©."


        logger.info(f"Main Assistant Node: Ph·∫£n h·ªìi cu·ªëi c√πng: '{final_answer}'")

        return {
            "messages": [AIMessage(content=final_answer)],
            "final_answer": final_answer,
            "clarification_needed": False
        }

    except Exception as e:
        logger.error(f"L·ªói trong Main Assistant Node: {e}", exc_info=True)
        error_message = f"Xin l·ªói, Amber ƒë√£ g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n: {str(e)[:100]}..."
         
        return {
            "messages": [AIMessage(content=error_message)],
            "final_answer": error_message,
            "clarification_needed": False
        }

# Placeholder cho node x·ª≠ l√Ω l·ªói (n·∫øu c·∫ßn)
async def error_handler_node(state: AmelaReactCompatibleAgentState) -> dict: # S·ª≠a ki·ªÉu tr·∫£ v·ªÅ
    logger.error("--- B·∫Øt ƒë·∫ßu Error Handler Node ---")
    error_message = state.get("error_message", "ƒê√£ c√≥ l·ªói kh√¥ng x√°c ƒë·ªãnh x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i.")
    logger.info(f"Error Handler Node: Th√¥ng b√°o l·ªói: '{error_message}'")
    return {
        "messages": [AIMessage(content=error_message)], # C·∫≠p nh·∫≠t messages
        "final_answer": error_message,
        "clarification_needed": False
    }