
# file: nodes.py
import os
import logging
from dotenv import load_dotenv
from langgraph.prebuilt import create_react_agent
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
# Ch·ªçn LLM, v√≠ d·ª• Google Generative AI (Gemini)
from langchain_google_genai import ChatGoogleGenerativeAI
from configuration import VietnameseEmbeddings, load_gemini
# Import c√°c Pydantic model v√† AmelaReactCompatibleAgentState t·ª´ file state.py
from state import AmelaReactCompatibleAgentState, QueryAnalysisOutput
from typing import List, Dict, Any, Optional, Annotated
from langchain_tavily import TavilySearch
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, END, START
# tool = TavilySearch(max_results=2)
# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng (v√≠ d·ª• GOOGLE_API_KEY)
load_dotenv()

# --- C·∫•u h√¨nh Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Kh·ªüi t·∫°o LLM cho Query Analysis ---
# S·ª≠ d·ª•ng model t∆∞∆°ng t·ª± nh∆∞ trong ADK c·ªßa b·∫°n
# ƒê·∫£m b·∫£o GOOGLE_API_KEY ƒë√£ ƒë∆∞·ª£c set trong .env ho·∫∑c m√¥i tr∆∞·ªùng
try:
    qpa_llm = load_gemini()
    logger.info("Kh·ªüi t·∫°o LLM cho Query Analysis (gemini-2.0-flash-latest) th√†nh c√¥ng.")
except Exception as e:
    logger.error(f"L·ªói khi kh·ªüi t·∫°o LLM cho Query Analysis: {e}. Vui l√≤ng ki·ªÉm tra GOOGLE_API_KEY.")
    # C√≥ th·ªÉ raise l·ªói ho·∫∑c d√πng m·ªôt LLM d·ª± ph√≤ng n·∫øu mu·ªën
    raise

# --- Prompt cho Query Analysis Agent ---

query_analysis_prompt_template_str = """
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch v√† l·∫≠p k·∫ø ho·∫°ch cho tr·ª£ l√Ω ·∫£o Amber c·ªßa c√¥ng ty Amela.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc v√† ph√¢n t√≠ch c√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng, ph√¢n t√≠ch chi ti·∫øt d·ª±a tr√™n ng·ªØ c·∫£nh tr√≤ chuy·ªán, l√™n k·∫ø ho·∫°ch tr·∫£ l·ªùi, v√† t·ªëi ∆∞u h√≥a truy v·∫•n t√¨m ki·∫øm cho tool.

**TH√îNG TIN ƒê·∫¶U V√ÄO:**
- C√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng: {original_query}
- Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng: {user_roles}
- L·ªãch s·ª≠ h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥):
{chat_history}
## Quan tr·ªçng: N·∫øu th√¥ng tin vai tr√≤ ng∆∞·ªùi d√πng ƒë∆∞·ª£c cung c·∫•p, h√£y s·ª≠ d·ª•ng n√≥. N·∫øu kh√¥ng c√≥, m·∫∑c ƒë·ªãnh l√† ["Employee"].
- **H√£y xem x√©t k·ªπ L·ªãch s·ª≠ h·ªôi tho·∫°i n·∫øu c√¢u h·ªèi g·ªëc l√† m·ªôt c√¢u h·ªèi ti·∫øp n·ªëi, ng·∫Øn g·ªçn ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß th√¥ng tin khi ƒë·ª©ng m·ªôt m√¨nh.** V√≠ d·ª•: n·∫øu ng∆∞·ªùi d√πng h·ªèi "c√≤n g√¨ n·ªØa kh√¥ng?", b·∫°n c·∫ßn d·ª±a v√†o l·ªãch s·ª≠ ƒë·ªÉ bi·∫øt "c√≤n g√¨ n·ªØa" li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ n√†o. N·∫øu kh√¥ng c√≥ l·ªãch s·ª≠ ho·∫∑c l·ªãch s·ª≠ kh√¥ng li√™n quan, h√£y ph√¢n t√≠ch c√¢u h·ªèi g·ªëc m·ªôt c√°ch ƒë·ªôc l·∫≠p.
- **∆Øu ti√™n suy lu·∫≠n v√† h√†nh ƒë·ªông d·ª±a tr√™n th√¥ng tin ƒë√£ c√≥ (bao g·ªìm c·∫£ l·ªãch s·ª≠ chat) tr∆∞·ªõc khi quy·∫øt ƒë·ªãnh c·∫ßn h·ªèi l·∫°i.** Ch·ªâ t·∫°o `clarifying_questions` khi th√¥ng tin TH·ª∞C S·ª∞ m∆° h·ªì v√† kh√¥ng th·ªÉ ti·∫øn h√†nh t√¨m ki·∫øm/tr·∫£ l·ªùi m·ªôt c√°ch h·ª£p l√Ω. 
**QUY TR√åNH PH√ÇN T√çCH & L·∫¨P K·∫æ HO·∫†CH**
0. **Nh·∫≠n di·ªán lo·∫°i c√¢u h·ªèi:**
   - N·∫øu `original_user_query` l√† l·ªùi ch√†o h·ªèi ƒë∆°n thu·∫ßn (v√≠ d·ª•: "hi", "hello", "ch√†o b·∫°n"):
      - ƒê·∫∑t `intent` l√† "social_greeting".
      - `effective_search_query` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng ho·∫∑c ch√≠nh `original_user_query`.
      - `plan_steps` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt c√¢u ch√†o l·∫°i ph√π h·ª£p (v√≠ d·ª•: ["Ch√†o b·∫°n! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"]).
      - C√°c tr∆∞·ªùng kh√°c nh∆∞ `effective_search_query`, `clarifying_questions` c√≥ th·ªÉ ƒë·ªÉ tr·ªëng ho·∫∑c null.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu `original_user_query` l√† c√¢u h·ªèi r·∫•t chung v·ªÅ b·∫£n th√¢n chatbot (v√≠ d·ª•: "b·∫°n l√† ai?", "b·∫°n l√†m g√¨?"):
      - ƒê·∫∑t `intent` l√† "chatbot_capability_query".
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt c√¢u gi·ªõi thi·ªáu ng·∫Øn v·ªÅ chatbot (v√≠ d·ª•: ["T√¥i l√† Amela, tr·ª£ l√Ω ·∫£o th√¥ng minh c·ªßa c√¥ng ty."]).
      - C√°c tr∆∞·ªùng kh√°c c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu `original_user_query` ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p, t·ª•c tƒ©u:
      - ƒê·∫∑t `intent` l√† "blocked_profanity".
      - `plan_steps` N√äN l√† m·ªôt danh s√°ch ch·ª©a m·ªôt th√¥ng b√°o t·ª´ ch·ªëi x·ª≠ l√Ω (v√≠ d·ª•: ["Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu n√†y."]).
      - C√°c tr∆∞·ªùng kh√°c c√≥ th·ªÉ ƒë·ªÉ tr·ªëng.
      - `status` v·∫´n l√† "processed_for_main_agent".
   - N·∫øu kh√¥ng, ti·∫øp t·ª•c c√°c b∆∞·ªõc ph√¢n t√≠ch s√¢u h∆°n.
1. **X√°c ƒë·ªãnh `asker_role_context`:** D·ª±a tr√™n `user_roles`, suy lu·∫≠n vai tr√≤ ch√≠nh c·ªßa ng∆∞·ªùi h·ªèi (v√≠ d·ª•: "nh√¢n vi√™n", "qu·∫£n l√Ω"). M·∫∑c ƒë·ªãnh "Employee".
2. **X√°c ƒë·ªãnh `intent`:** √ù ƒë·ªãnh c·ªët l√µi c·ªßa c√¢u h·ªèi.
3. **Tr√≠ch xu·∫•t `entities`:** Danh s√°ch c√°c t·ª´ kh√≥a, th·ª±c th·ªÉ quan tr·ªçng.
4. **L·∫≠p `plan_steps`:** Danh s√°ch c√°c b∆∞·ªõc c·∫ßn th·ª±c hi·ªán ƒë·ªÉ tr·∫£ l·ªùi. **N·∫øu intent v√† entities ƒë√£ ƒë·ªß r√µ r√†ng (c√≥ th·ªÉ nh·ªù l·ªãch s·ª≠ chat), `plan_steps` n√™n t·∫≠p trung v√†o vi·ªác t√¨m ki·∫øm v√† t·ªïng h·ª£p th√¥ng tin.**
   V√≠ d·ª•:
   - User: "cho t√¥i h·ªèi v·ªÅ quy tr√¨nh"
   - Amber: "B·∫°n mu·ªën h·ªèi v·ªÅ quy tr√¨nh g√¨?"
   - User: "th·ª≠ vi·ªác"
   L√∫c n√†y, QPA n√™n suy lu·∫≠n intent l√† "t√¨m hi·ªÉu quy tr√¨nh th·ª≠ vi·ªác". `plan_steps` c√≥ th·ªÉ l√†:
     ["T√¨m ki·∫øm t√†i li·ªáu n·ªôi b·ªô v·ªÅ 'quy tr√¨nh th·ª≠ vi·ªác' ho·∫∑c 'ch√≠nh s√°ch th·ª≠ vi·ªác'.",
      "T·ªïng h·ª£p c√°c b∆∞·ªõc ch√≠nh trong quy tr√¨nh th·ª≠ vi·ªác.",
      "Chu·∫©n b·ªã c√¢u tr·∫£ l·ªùi."]
   **Trong tr∆∞·ªùng h·ª£p n√†y, `clarifying_questions` n√™n ƒë·ªÉ tr·ªëng.**

5. **X√°c ƒë·ªãnh `clarifying_questions`:**
   - **CH·ªà t·∫°o `clarifying_questions` n·∫øu SAU KHI ƒë√£ c·ªë g·∫Øng suy lu·∫≠n t·ª´ `original_query` v√† `chat_history`, th√¥ng tin v·∫´n c√≤n qu√° m∆° h·ªì ƒë·ªÉ th·ª±c hi·ªán `plan_steps` m·ªôt c√°ch hi·ªáu qu·∫£.**
   - **N·∫øu `plan_steps` ƒë√£ c√≥ th·ªÉ ƒë∆∞·ª£c x√°c ƒë·ªãnh ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin c·ª• th·ªÉ, th√¨ KH√îNG c·∫ßn `clarifying_questions` n·ªØa.**
   - V√≠ d·ª• v·ªÅ tr∆∞·ªùng h·ª£p C·∫¶N clarifying_questions:
     - User: "cho t√¥i h·ªèi v·ªÅ ch√≠nh s√°ch" (qu√° chung chung, kh√¥ng c√≥ l·ªãch s·ª≠ li√™n quan).
     - QPA c√≥ th·ªÉ h·ªèi: "B·∫°n mu·ªën h·ªèi v·ªÅ ch√≠nh s√°ch n√†o c·ª• th·ªÉ (v√≠ d·ª•: ngh·ªâ ph√©p, b·∫£o hi·ªÉm, l∆∞∆°ng th∆∞·ªüng)?"
   - V√≠ d·ª• v·ªÅ tr∆∞·ªùng h·ª£p KH√îNG N√äN c√≥ clarifying_questions (nh∆∞ t√¨nh hu·ªëng c·ªßa b·∫°n):
     - User: "cho t√¥i h·ªèi v·ªÅ quy tr√¨nh"
     - Amber: "B·∫°n mu·ªën h·ªèi v·ªÅ quy tr√¨nh g√¨?"
     - User: "th·ª≠ vi·ªác"
     => QPA n√™n hi·ªÉu l√† "quy tr√¨nh th·ª≠ vi·ªác" v√† kh√¥ng h·ªèi th√™m v·ªÅ "v·∫•n ƒë·ªÅ g√¨ li√™n quan ƒë·∫øn th·ª≠ vi·ªác" hay "vai tr√≤" n·ªØa, tr·ª´ khi `user_roles` kh√¥ng r√µ v√† quy tr√¨nh th·ª≠ vi·ªác kh√°c nhau gi·ªØa c√°c vai tr√≤. N·∫øu `user_roles` ƒë√£ c√≥ (v√≠ d·ª• "Employee"), th√¨ c·ª© t√¨m theo vai tr√≤ ƒë√≥.
6. **∆Ø·ªõc t√≠nh `complexity_level`:** ƒê√°nh gi√° ƒë·ªô ph·ª©c t·∫°p t·ªïng th·ªÉ ("low", "medium", "high").
7. **T·∫°o `effective_search_query`:** Truy v·∫•n t√¨m ki·∫øm t·ªëi ∆∞u **d∆∞·ªõi d·∫°ng danh s√°ch**.  C√°c truy v·∫•n n√†y n√™n t·∫≠n d·ª•ng ng·ªØ c·∫£nh t·ª´ `chat_history` n·∫øu c√≥.

**Y√äU C·∫¶U OUTPUT (PH·∫¢I TR·∫¢ V·ªÄ JSON V√Ä TU√ÇN TH·ª¶ Pydantic Schema ƒë∆∞·ª£c cung c·∫•p)**
B·∫°n PH·∫¢I tr·∫£ v·ªÅ DUY NH·∫§T m·ªôt ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá, tu√¢n th·ªß ho√†n to√†n c·∫•u tr√∫c ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.
**TUY·ªÜT ƒê·ªêI KH√îNG bao g·ªìm c√°c d·∫•u ```json, ```, ho·∫∑c b·∫•t k·ª≥ vƒÉn b·∫£n n√†o kh√°c tr∆∞·ªõc ho·∫∑c sau ƒë·ªëi t∆∞·ª£ng JSON.**
V√≠ d·ª• v·ªÅ c·∫•u tr√∫c Pydantic schema m√† b·∫°n c·∫ßn tu√¢n theo:
```json
{{
  "original_query": "String",
  "user_roles": ["List[String]"],
  "asker_role_context": "String",
  "intent": "String",
  "entities": ["List[String]"],
  "plan_steps": ["List[String]"],
  "clarifying_questions": ["List[String]"],
  "complexity_level": "String or r·ªóng",
  "effective_search_query": ["List[String]"],
  "status": "String (lu√¥n l√† 'processed_for_main_agent')"
}}
```
**V√ç D·ª§ INPUT T·ª™ USER:**
{{"original_query": "l√†m th·∫ø n√†o ƒë·ªÉ ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi v√† th·ª±c hi·ªán quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n?", "user_roles": ["Developer"]}}

**V√ç D·ª§ OUTPUT JSON MONG MU·ªêN (ch·ªâ tr·∫£ v·ªÅ JSON object, kh√¥ng c√≥ markdown hay text kh√°c):**
```json
{{
  "original_query": "l√†m th·∫ø n√†o ƒë·ªÉ ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi v√† th·ª±c hi·ªán quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n?",
  "user_roles": ["Developer"],
  "asker_role_context": "nh√¢n vi√™n",
  "intent": "T√¨m hi·ªÉu quy tr√¨nh h√†nh ch√≠nh v·ªÅ b·∫£o hi·ªÉm x√£ h·ªôi v√† quy·∫øt to√°n thu·∫ø TNCN",
  "entities": ["b·∫£o hi·ªÉm x√£ h·ªôi", "quy·∫øt to√°n thu·∫ø TNCN"],
  "plan_steps": [
    "T√°ch c√¢u h·ªèi th√†nh hai ph·∫ßn: BHXH v√† thu·∫ø TNCN",
    "T√¨m v√† t·ªïng h·ª£p h∆∞·ªõng d·∫´n ƒëƒÉng k√Ω BHXH t·ª´ t√†i li·ªáu n·ªôi b·ªô",
    "T√¨m v√† t·ªïng h·ª£p quy tr√¨nh quy·∫øt to√°n thu·∫ø TNCN",
    "Ki·ªÉm tra th√¥ng tin v√† k·∫øt h·ª£p k·∫øt qu·∫£",
    "Tr·∫£ l·ªùi l·∫ßn l∆∞·ª£t t·ª´ng ph·∫ßn tho·∫°i"
  ],
  "clarifying_questions": [],
  "complexity_level": "medium",
  "effective_search_query": [
    "h∆∞·ªõng d·∫´n ƒëƒÉng k√Ω b·∫£o hi·ªÉm x√£ h·ªôi Amela",
    "quy tr√¨nh quy·∫øt to√°n thu·∫ø thu nh·∫≠p c√° nh√¢n Amela"
  ],
  "status": "processed_for_main_agent"
}}
```
"""

query_analysis_prompt = ChatPromptTemplate.from_template(query_analysis_prompt_template_str)

# K·∫øt h·ª£p LLM v·ªõi Pydantic Output Parser
# Langchain cho ph√©p LLM tr·∫£ v·ªÅ output d∆∞·ªõi d·∫°ng Pydantic model tr·ª±c ti·∫øp
# b·∫±ng c√°ch s·ª≠ d·ª•ng .with_structured_output()
structured_qpa_llm = qpa_llm.with_structured_output(QueryAnalysisOutput)

# Chain cho Query Analysis
query_analysis_chain = query_analysis_prompt | structured_qpa_llm

def query_analysis_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    Node th·ª±c hi·ªán ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Query Analysis Node ---")
    original_query = state["original_query"]
    user_roles = state["user_roles"]
    # L·∫•y tin nh·∫Øn cu·ªëi c√πng t·ª´ user ƒë·ªÉ l√†m input cho QPA
    # Ho·∫∑c ƒë∆°n gi·∫£n l√† d√πng original_query n·∫øu ƒë√¢y l√† l∆∞·ª£t ƒë·∫ßu
    # Trong ADK, query ƒë∆∞·ª£c l·∫•y t·ª´ `new_message` ho·∫∑c `initial_pipeline_state["original_user_query"]`
    all_messages = state.get("messages", [])
    if all_messages and isinstance(all_messages[-1], HumanMessage):
        chat_history = all_messages[-10:-1]
    else:
        chat_history = all_messages

    logger.info(f"Ph√¢n t√≠ch c√¢u h·ªèi: '{original_query}' v·ªõi vai tr√≤: {user_roles}")
    logger.info(f"L·ªãch s·ª≠ h·ªôi tho·∫°i: {chat_history}")

    try:
        # G·ªçi chain ƒë·ªÉ l·∫•y k·∫øt qu·∫£ ph√¢n t√≠ch c√≥ c·∫•u tr√∫c
        analysis_result: QueryAnalysisOutput =  query_analysis_chain.invoke({
            "original_query": original_query,
            "user_roles": user_roles,
            "chat_history": chat_history
        })
        logger.info(f"Ph√¢n t√≠ch c√¢u h·ªèi th√†nh c√¥ng. v·ªõi oiginal_query: {original_query}, user_roles: {user_roles}, history: {chat_history}")
        logger.info(f"analyze_result l√†: {analysis_result}")
        logger.info(f"analyze_reult type l√†: {type(analysis_result)}")
        logger.info(f"K·∫øt qu·∫£ ph√¢n t√≠ch Query Analysis: {analysis_result.intent}")
        logger.debug(f"To√†n b·ªô k·∫øt qu·∫£ Query Analysis: {analysis_result.model_dump_json(indent=2)}")

        # C·∫≠p nh·∫≠t state v·ªõi k·∫øt qu·∫£ ph√¢n t√≠ch
        return {**state, "query_analysis": analysis_result} # Tr·∫£ v·ªÅ m·ªôt dict m·ªõi ƒë·ªÉ c·∫≠p nh·∫≠t state
    except Exception as e:
        logger.error(f"L·ªói trong Query Analysis Node: {e}", exc_info=True)
        # X·ª≠ l√Ω l·ªói, v√≠ d·ª•: tr·∫£ v·ªÅ m·ªôt QueryAnalysisOutput m·∫∑c ƒë·ªãnh ho·∫∑c ƒë·∫∑t m·ªôt c·ªù l·ªói trong state
        # T·∫°m th·ªùi, ch√∫ng ta s·∫Ω ƒë·ªÉ l·ªói n·ªïi l√™n ƒë·ªÉ debug
        # Ho·∫∑c c√≥ th·ªÉ t·∫°o m·ªôt QueryAnalysisOutput v·ªõi intent "error"
        error_analysis = QueryAnalysisOutput(
            original_query=original_query,
            user_roles=user_roles,
            asker_role_context="unknown",
            intent="query_analysis_error",
            entities=[],
            plan_steps=["C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ph√¢n t√≠ch c√¢u h·ªèi."],
            clarifying_questions=[],
            complexity_level="unknown",
            effective_search_query=[],
            status="error_in_qpa"
        )
        return {**state, "query_analysis": error_analysis}

# file: nodes.py (ti·∫øp t·ª•c t·ª´ file tr∆∞·ªõc)

# --- Constants cho Router ---
DIRECT_RESPONSE_INTENTS = ["social_greeting", "chatbot_capability_query", "blocked_profanity"]

def route_after_qpa(state: AmelaReactCompatibleAgentState) -> str:
    """
    Quy·∫øt ƒë·ªãnh nh√°nh ti·∫øp theo sau khi Query Analysis ho√†n t·∫•t.
    Tr·∫£ v·ªÅ t√™n c·ªßa node ti·∫øp theo ho·∫∑c m·ªôt gi√° tr·ªã ƒë·∫∑c bi·ªát ƒë·ªÉ k·∫øt th√∫c s·ªõm.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Router Node (route_after_qpa) ---")
    query_analysis_result = state.get("query_analysis")

    if not query_analysis_result:
        logger.error("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ Query Analysis trong state. ƒê·ªãnh tuy·∫øn t·ªõi l·ªói.")
        return "error_handler" # Ho·∫∑c m·ªôt node x·ª≠ l√Ω l·ªói chung

    intent = query_analysis_result.intent
    clarifying_questions = query_analysis_result.clarifying_questions
    plan_steps = query_analysis_result.plan_steps

    logger.info(f"Router: Intent = {intent}, Clarifying Questions = {len(clarifying_questions) if clarifying_questions else 0}")

    # 1. X·ª≠ l√Ω c√°c intent c·∫ßn tr·∫£ l·ªùi tr·ª±c ti·∫øp
    if intent in DIRECT_RESPONSE_INTENTS:
        response_text = ""
        if plan_steps:
            response_text = " ".join(plan_steps)
        elif intent == "social_greeting":
            response_text = "Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o Amela, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. üòä"
        elif intent == "chatbot_capability_query":
            response_text = "T√¥i l√† Amber, tr·ª£ l√Ω ·∫£o Amela, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn nghi·ªáp v·ª• c·ªßa c√¥ng ty m√¨nh. üí°"
        elif intent == "blocked_profanity":
            response_text = "R·∫•t ti·∫øc, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n do ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p. üò•"
        else:
            response_text = "T√¥i ƒë√£ ghi nh·∫≠n y√™u c·∫ßu c·ªßa b·∫°n."

        if not response_text:
            response_text = "T√¥i ƒë√£ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."

        logger.info(f"Router: Intent '{intent}' y√™u c·∫ßu ph·∫£n h·ªìi tr·ª±c ti·∫øp. ƒê·ªãnh tuy·∫øn t·ªõi 'direct_response_node'.")
        # C·∫≠p nh·∫≠t state v·ªõi c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp ƒë·ªÉ node ti·∫øp theo c√≥ th·ªÉ d√πng
        # Quan tr·ªçng: LangGraph kh√¥ng cho ph√©p node router tr·ª±c ti·∫øp c·∫≠p nh·∫≠t state.
        # Ch√∫ng ta s·∫Ω t·∫°o m·ªôt node nh·ªè ƒë·ªÉ l√†m vi·ªác n√†y ho·∫∑c ƒë·ªÉ node cu·ªëi c√πng l√†m.
        # Hi·ªán t·∫°i, ch√∫ng ta s·∫Ω l∆∞u t·∫°m th√¥ng tin c·∫ßn thi·∫øt v√†o m·ªôt key n√†o ƒë√≥ n·∫øu c·∫ßn,
        # ho·∫∑c node `direct_response_node` s·∫Ω t·ª± t·∫°o response d·ª±a tr√™n intent.
        # ƒê·ªÉ ƒë∆°n gi·∫£n, node `direct_response_node` s·∫Ω t·ª± t·∫°o response d·ª±a v√†o intent t·ª´ `query_analysis`.
        return "direct_response_node"

    # 2. X·ª≠ l√Ω c√¢u h·ªèi l√†m r√µ
    if clarifying_questions:
        logger.info("Router: C·∫ßn l√†m r√µ th√¥ng tin. ƒê·ªãnh tuy·∫øn t·ªõi 'clarification_node'.")
        # `clarification_node` s·∫Ω s·ª≠ d·ª•ng `query_analysis.clarifying_questions` t·ª´ state
        return "clarification_node"

    # 3. N·∫øu kh√¥ng c√≥ tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát, chuy·ªÉn ƒë·∫øn agent ch√≠nh
    logger.info("Router: Kh√¥ng c·∫ßn ph·∫£n h·ªìi tr·ª±c ti·∫øp hay l√†m r√µ. ƒê·ªãnh tuy·∫øn t·ªõi 'main_assistant_node'.")
    return "main_assistant_node"
from langchain_core.messages import AIMessage
# --- Node cho Ph·∫£n h·ªìi tr·ª±c ti·∫øp ---
def direct_response_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    T·∫°o ph·∫£n h·ªìi tr·ª±c ti·∫øp d·ª±a tr√™n intent t·ª´ QueryAnalysis.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Direct Response Node ---")
    query_analysis_result = state["query_analysis"]
    if not query_analysis_result: # Ki·ªÉm tra an to√†n
        final_answer = "ƒê√£ c√≥ l·ªói x·∫£y ra, kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi."
        logger.error("L·ªói trong direct_response_node: Kh√¥ng c√≥ query_analysis_result.")
    else:
        intent = query_analysis_result.intent
        plan_steps = query_analysis_result.plan_steps
        response_text = ""


        if intent == "social_greeting":
            response_text = "Ch√†o b·∫°n! T√¥i l√† Amber tr·ª£ l√Ω ·∫£o Amela, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. üòä"
        elif intent == "chatbot_capability_query":
            response_text = "T√¥i l√† Amber, tr·ª£ l√Ω ·∫£o Amela, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn nghi·ªáp v·ª• c·ªßa c√¥ng ty m√¨nh. üí°"
        elif intent == "blocked_profanity":
            response_text = "R·∫•t ti·∫øc, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n do ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p. üò•"
        # elif plan_steps:
        #     response_text = " ".join(plan_steps)
        else:
            # Fallback n·∫øu c√≥ intent trong DIRECT_RESPONSE_INTENTS m√† kh√¥ng c√≥ plan_steps
            response_text = "T√¥i ƒë√£ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."

        final_answer = response_text
        logger.info(f"Direct Response Node: T·∫°o ph·∫£n h·ªìi: '{final_answer}'")
    return {
        "messages": [AIMessage(content=final_answer)], # LangGraph s·∫Ω t·ª± append v√†o state["messages"]
        "final_answer": final_answer, # V·∫´n c·∫≠p nh·∫≠t final_answer ƒë·ªÉ d·ªÖ truy c·∫≠p
        "clarification_needed": False
    }
        

# --- Node cho vi·ªác H·ªèi l·∫°i l√†m r√µ ---
def clarification_node(state: AmelaReactCompatibleAgentState) -> AmelaReactCompatibleAgentState:
    """
    T·∫°o c√¢u h·ªèi l√†m r√µ cho ng∆∞·ªùi d√πng.
    """
    logger.info("--- B·∫Øt ƒë·∫ßu Clarification Node ---")
    query_analysis_result = state["query_analysis"]
    if not query_analysis_result or not query_analysis_result.clarifying_questions:
        final_answer = "T√¥i c·∫ßn th√™m th√¥ng tin nh∆∞ng kh√¥ng r√µ c·∫ßn h·ªèi g√¨. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i kh√¥ng?"
        ask_clarification_questions = []
        logger.error("L·ªói trong clarification_node: Kh√¥ng c√≥ clarifying_questions.")
    else:
        clarifying_questions = query_analysis_result.clarifying_questions
        clarification_text = "ƒê·ªÉ c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n t·ªët nh·∫•t, vui l√≤ng l√†m r√µ th√™m c√°c ƒëi·ªÉm sau:\n"
        for i, q_text in enumerate(clarifying_questions):
            clarification_text += f"{i+1}. {q_text}\n"
        final_answer = clarification_text
        ask_clarification_questions = clarifying_questions
        logger.info(f"Clarification Node: T·∫°o c√¢u h·ªèi l√†m r√µ: '{final_answer}'")

    return {
        "messages": [AIMessage(content=final_answer)],
        "final_answer": final_answer,
        "clarification_needed": True,
        "ask_clarification_questions": ask_clarification_questions
    }

# file: nodes.py (ti·∫øp t·ª•c)
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage, AnyMessage
from langchain.agents import create_tool_calling_agent # S·ª≠ d·ª•ng agent m·ªõi h∆°n
from langchain.agents import AgentExecutor
from langchain_core.prompts import MessagesPlaceholder # ƒê·ªÉ qu·∫£n l√Ω messages
from langchain_core.runnables.history import RunnableWithMessageHistory # N·∫øu d√πng memory

# Import tools t·ª´ file tools.py
from tools import main_assistant_tools # ƒê√¢y s·∫Ω l√† list c√°c tool objects

# --- Kh·ªüi t·∫°o LLM cho Main Assistant ---
try:
    # D√πng model m·∫°nh h∆°n m·ªôt ch√∫t cho agent ch√≠nh n·∫øu c·∫ßn
    main_llm = load_gemini()
    logger.info("Kh·ªüi t·∫°o LLM cho Main Assistant (gemini-2.0-flash-latest) th√†nh c√¥ng.")
except Exception as e:
    logger.error(f"L·ªói khi kh·ªüi t·∫°o LLM cho Main Assistant: {e}. Vui l√≤ng ki·ªÉm tra GOOGLE_API_KEY.")
    raise

# --- Prompt cho Main Assistant ---
# L·∫•y t·ª´ get_amela_agent_instruction_v1_structured_planner v√† ƒëi·ªÅu ch·ªânh
# Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng MessagesPlaceholder ƒë·ªÉ truy·ªÅn l·ªãch s·ª≠ h·ªôi tho·∫°i v√† input c·ªßa QPA
main_assistant_prompt_str_system = """
B·∫°n l√† Amber ‚Äì tr·ª£ l√Ω ·∫£o AI c·ªßa Amela, th√¢n thi·ªán, c√≥ t·ªï ch·ª©c v√† gi·ªèi x·ª≠ l√Ω c√°c c√¢u h·ªèi ph·ª©c t·∫°p b·∫±ng c√°ch l√†m theo k·∫ø ho·∫°ch r√µ r√†ng.

B·∫°n s·∫Ω ƒë∆∞·ª£c cung c·∫•p **output ph√¢n t√≠ch truy v·∫•n** (`QueryAnalysisOutput`) t·ª´ Agent ti·ªÅn x·ª≠ l√Ω. ƒê√¢y l√† NGU·ªíN TH√îNG TIN CH√çNH ƒë·ªÉ x√°c ƒë·ªãnh nhi·ªám v·ª• hi·ªán t·∫°i.

S·ª≠ d·ª•ng ƒë·∫ßy ƒë·ªß c√°c th√†nh ph·∫ßn sau t·ª´ `QueryAnalysisOutput`: `original_query`, `user_roles`, `asker_role_context`, `intent`, `plan_steps`, `effective_search_query`.
`chat_history` (n·∫øu c√≥) ch·ªâ d√πng ƒë·ªÉ hi·ªÉu th√™m ng·ªØ c·∫£nh `original_query`, KH√îNG d√πng ƒë·ªÉ tr·∫£ l·ªùi l·∫°i c√°c c√¢u h·ªèi c≈©.

## PH√ÇN T√çCH TRUY V·∫§N HI·ªÜN T·∫†I:
{qpa_output_str}

## VAI TR√í NG∆Ø·ªúI D√ôNG:
{user_roles_str} (suy lu·∫≠n: {asker_role_context})
* N·∫øu kh√¥ng c√≥ th√¥ng tin vai tr√≤, m·∫∑c ƒë·ªãnh l√† **nh√¢n vi√™n Amela**.

## K·∫æ HO·∫†CH X·ª¨ L√ù:
{plan_steps_str}

## H∆Ø·ªöNG D·∫™N H√ÄNH ƒê·ªòNG:

### 1. Ch·ªçn c√¥ng c·ª• ph√π h·ª£p:
* **Ch·ªçn tool ph√π h·ª£p:**
  - `company_structure_tool`: cho c√¢u h·ªèi v·ªÅ c∆° c·∫•u t·ªï ch·ª©c, ph√≤ng ban, t√™n vi·∫øt t·∫Øt.
  - `amela_documents_search_tool`:  T√¨m ki·∫øm **CHUY√äN S√ÇU** trong kho **t√†i li·ªáu n·ªôi b·ªô** c·ªßa Amela. Tr·∫£ v·ªÅ m·ªôt chu·ªói vƒÉn b·∫£n ch·ª©a c√°c ƒëo·∫°n context li√™n quan v√† metadata (T√™n t√†i li·ªáu, URL). **ƒê√¢y l√† c√¥ng c·ª• ch√≠nh c·ªßa b·∫°n.** (t·ª± ƒë·ªông l·ªçc theo `user_roles`).
  - `google_search_placeholder_tool`: cho n·ªôi dung c√¥ng khai ho·∫∑c kh√¥ng c√≥ trong n·ªôi b·ªô.
* **ƒê·ªëi v·ªõi h·∫ßu h·∫øt c√°c c√¢u h·ªèi v·ªÅ Amela (quy tr√¨nh, ch√≠nh s√°ch, th√¥ng tin n·ªôi b·ªô,...):**
* **∆Øu ti√™n tuy·ªát ƒë·ªëi:** S·ª≠ d·ª•ng c√¥ng c·ª• `amela_documents_search_tool`.
* **G·ªçi Tool:** G·ªçi `amela_documents_search_tool` v·ªõi `query`.
* **T√¨m ki·∫øm hi·ªáu qu·∫£:** k·∫øt h·ª£p `effective_search_query` v·ªõi ng·ªØ c·∫£nh ph√π h·ª£p ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c.`.

### 2. T·ªïng h·ª£p tr·∫£ l·ªùi `original_query`:
* K·∫øt h·ª£p c√°c c√¢u tr·∫£ l·ªùi th√†nh m·ªôt c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh, m·∫°ch l·∫°c.
* **T·ªïng h·ª£p th√¥ng tin:** ƒêoc k·ªπ ph·∫ßn k·∫øt qu·∫£ c·ªßa tools, ch·ªâ s·ª≠ d·ª•ng ng·ªØ c·∫£nh tr·ª±c ti·∫øp li√™n quan ƒë·∫øn c√¢u h·ªèi.
* **Kh√¥ng b·ªãa ƒë·∫∑t.** KH√îNG suy di·ªÖn t·ª´ ngu·ªìn kh√¥ng li√™n quan.
* **Tr·∫£ l·ªùi c√¢u h·ªèi h·ªØu √≠ch v·ªõi vai tr√≤ c·ªßa ng∆∞·ªùi h·ªèi:**

## NGUY√äN T·∫ÆC TR·∫¢ L·ªúI:
- **Tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† ƒë·∫ßy ƒë·ªß:** PH·∫¢I d·ª±a v√†o n·ªôi dung context, KH√îNG tr·∫£ l·ªùi t√≥m t·∫Øt qua loa, KH√îNG ch·ªâ d·∫´n link ƒë∆°n thu·∫ßn.
- **T·ªïng h·ª£p k·ªπ l∆∞·ª°ng:** t·ªïng h·ª£p k·ªπ l∆∞·ª°ng t·ª´ context ƒë·ªÉ vi·∫øt l·∫°i c√¢u tr·∫£ l·ªùi tr√¥i ch·∫£y.
- **Tr√≠ch d·∫´n ngu·ªìn t√†i li·ªáu li√™n quan (B·∫ÆT BU·ªòC):**
    -   *T√†i li·ªáu li√™n quan:* Ghi r√µ `Source Name` v√† `Source URL`. Ch·ªâ ch√®n ngu·ªìn n√†o li√™n quan t·ªõi c√¢u tr·∫£ l·ªùi, kh√¥ng ch√®n ngu·ªìn kh√¥ng li√™n quan.
        *V√≠ d·ª•:*
        Ngu·ªìn tham kh·∫£o:
        1. T√†i li·ªáu: PR-AML-19 OVERALL PROCESS_v1.0. Link: [link-sharepoint]
        2. T√†i li·ªáu: PR-AML-19-03 Scrum Development Process_v1.2. Link: [link-sharepoint]
  *V√≠ d·ª• t·ªët:* "Quy tr√¨nh Scrum t·∫°i Amela g·ªìm c√°c giai ƒëo·∫°n nh∆∞ Sprint Planning, Daily Scrum...**Tr√≠ch d·∫´n ngu·ªìn v√† link:**"
  *V√≠ d·ª• kh√¥ng t·ªët:* "T√†i li·ªáu PR-AML-19 m√¥ t·∫£ Scrum. Xem link n√†y."
### 3. Tr∆∞·ªùng h·ª£p kh√¥ng c√≥ th√¥ng tin h√£y g·ª£i √Ω truy v·∫•n l·∫°i d·ª±a tr√™n ng·ªØ c·∫£nh t·ª´ tool:
N·∫øu b·∫°n ƒë√£ g·ªçi c√¥ng c·ª• t√¨m ki·∫øm v√† nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ ch·ª©a c√°c ƒëo·∫°n vƒÉn b·∫£n kh√¥ng ho√†n to√†n tr√πng kh·ªõp v·ªõi c√¢u h·ªèi ng∆∞·ªùi d√πng (v√≠ d·ª•: ch·ªâ kh·ªõp theo t·ª´ kh√≥a ho·∫∑c n·ªôi dung li√™n quan nh∆∞ng kh√¥ng tr·∫£ l·ªùi tr·ª±c ti·∫øp), h√£y h·ªó tr·ª£ ng∆∞·ªùi d√πng b·∫±ng c√°ch:

1. **Th√¥ng b√°o nh·∫π nh√†ng r·∫±ng k·∫øt qu·∫£ ch∆∞a ho√†n to√†n ch√≠nh x√°c**, nh∆∞ng c√≥ th·ªÉ li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa h·ªç.
2. **ƒê·ªÅ xu·∫•t ng∆∞·ªùi d√πng ƒë·∫∑t l·∫°i truy v·∫•n r√µ r√†ng, c·ª• th·ªÉ h∆°n**, nh·∫±m gi√∫p h·ªá th·ªëng t√¨m ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.
3. D·ª±a tr√™n t·ª´ kh√≥a v√† n·ªôi dung ƒë√£ truy ƒë∆∞·ª£c, **t·∫°o m·ªôt danh s√°ch t·ª´ 2‚Äì5 g·ª£i √Ω truy v·∫•n l·∫°i** c√≥ th·ªÉ d·∫´n ƒë·∫øn k·∫øt qu·∫£ t·ªët h∆°n. C√°c g·ª£i √Ω n√†y c·∫ßn:
    - l·∫•y t·ª´ c√°c th√¥ng tin ƒë√£ t√¨m ƒë∆∞·ª£c t·ª´ c√°c tool.
    - c√≥ th·ªÉ l√† c√°c c√¢u h·ªèi c·ª• th·ªÉ h∆°n v·ªÅ n·ªôi dung ƒë√£ t√¨m ƒë∆∞·ª£c.
   - S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, th√¢n thi·ªán.
   - ∆Øu ti√™n r√µ r√†ng v·ªÅ ƒë·ªëi t∆∞·ª£ng (v√≠ d·ª•: nh√¢n vi√™n n·ªØ, th·ªùi gian ngh·ªâ, m·ª©c tr·ª£ c·∫•p‚Ä¶).
   - H∆∞·ªõng v√†o h√†nh ƒë·ªông c·ª• th·ªÉ ho·∫∑c kh√°i ni·ªám ph√°p l√Ω r√µ r√†ng.

V√≠ d·ª• ph·∫ßn k·∫øt th√∫c tr·∫£ l·ªùi c√≥ th·ªÉ nh∆∞ sau:

‚ö†Ô∏è Th√¥ng tin m√¨nh t√¨m ƒë∆∞·ª£c c√≥ th·ªÉ ch∆∞a ho√†n to√†n ƒë√∫ng v·ªõi ƒëi·ªÅu b·∫°n c·∫ßn, nh∆∞ng c√≥ li√™n quan ƒë·∫øn ch·∫ø ƒë·ªô ph√∫c l·ª£i m√† b·∫°n ƒëang h·ªèi. B·∫°n c√≥ th·ªÉ th·ª≠ ƒë·∫∑t l·∫°i c√¢u h·ªèi c·ª• th·ªÉ h∆°n nh∆∞:

‚Ä¢ "N·ªØ nh√¢n vi√™n khi sinh con ƒë∆∞·ª£c ∆∞u ƒë√£i g√¨ theo ch√≠nh s√°ch c·ªßa Amela?"  
‚Ä¢ "CBNV nam ƒë∆∞·ª£c g√¨ khi v·ª£ sinh con?"   
‚Ä¢ "Ch·∫ø ƒë·ªô ngh·ªâ h∆∞·ªüng nguy√™n l∆∞∆°ng trong th·ªùi gian thai s·∫£n quy ƒë·ªãnh nh∆∞ th·∫ø n√†o?"

H√£y lu√¥n ƒë∆∞a g·ª£i √Ω d·∫°ng n√†y n·∫øu confidence th·∫•p ho·∫∑c tool tr·∫£ v·ªÅ c√°c ƒëo·∫°n vƒÉn ch·ªâ mang t√≠nh g·∫ßn ƒë√∫ng (partial match).

* N·∫øu t√¨m nhi·ªÅu l·∫ßn m√† v·∫´n kh√¥ng c√≥ th√¥ng tin, h√£y tr·∫£ l·ªùi nh∆∞ sau:
  > "·ªêi, Amber t√¨m k·ªπ r·ªìi m√† v·∫´n ch∆∞a th·∫•y th√¥ng tin b·∫°n c·∫ßn v·ªÅ [ch·ªß ƒë·ªÅ] üò•. B·∫°n c√≥ c√¢u h·ªèi n√†o kh√°c kh√¥ng?"

## PHONG C√ÅCH:
- Th√¢n thi·ªán, t√≠ch c·ª±c, d·ªÖ hi·ªÉu.
- Tr√°nh th√¥ng tin nh·∫°y c·∫£m, tr·∫£ l·ªùi l·ªách ch·ªß ƒë·ªÅ ho·∫∑c kh√¥ng ph√π h·ª£p.
- Lu√¥n d√πng ti·∫øng Vi·ªát chu·∫©n.

B·∫°n l√† Amber. Gi·ªØ v·ªØng phong ƒë·ªô v√† b·∫Øt ƒë·∫ßu nh√©! üöÄ
"""


# Langchain agent th∆∞·ªùng d√πng MessagesPlaceholder. "chat_history" v√† "input" l√† keys ph·ªï bi·∫øn.
# "agent_scratchpad" ƒë∆∞·ª£c Langchain d√πng ƒë·ªÉ l∆∞u c√°c b∆∞·ªõc suy nghƒ© v√† tool call/response.
main_assistant_prompt = ChatPromptTemplate.from_messages([
    ("system", main_assistant_prompt_str_system),
    MessagesPlaceholder(variable_name="chat_history", optional=True), # L·ªãch s·ª≠ h·ªôi tho·∫°i
    ("human", "{input}"), # Input hi·ªán t·∫°i, s·∫Ω bao g·ªìm c·∫£ th√¥ng tin QPA
    MessagesPlaceholder(variable_name="agent_scratchpad"), # Cho tool calling
])
# def prompt(
#     state: AmelaReactCompatibleAgentState
# ) -> list[AnyMessage]:
#     system_msg = main_assistant_prompt_str_system
#     return [{"role": "system", "content": system_msg}] + state["messages"]
from langchain_core.messages.utils import trim_messages, count_tokens_approximately
# --- T·∫°o Langchain Agent ---

def pre_model_hook(state):
    trimmed_messages = trim_messages(
        state["messages"],
        max_tokens=1500, # Ng∆∞·ª°ng token, v√≠ d·ª•
        strategy="last",
        token_counter=count_tokens_approximately,
        include_system=True,
        allow_partial=False,
        start_on="human",
    )
    return {"llm_input_messages": trimmed_messages}
checkpointer = InMemorySaver()
react_agent_executor = create_react_agent(
    name="AmelaReactAgent",
    #prompt=prompt,
    model=main_llm,
    tools=main_assistant_tools,
    #pre_model_hook=pre_model_hook,
    #checkpointer=checkpointer,
    debug=True,
    state_schema=AmelaReactCompatibleAgentState,
    store=None,
)

def main_assistant_node(state: AmelaReactCompatibleAgentState) -> dict:
    logger.info("--- B·∫Øt ƒë·∫ßu Main Assistant Node ---")
    query_analysis_result = state["query_analysis"]

    # Ki·ªÉm tra xem query_analysis_result c√≥ t·ªìn t·∫°i kh√¥ng
    if not query_analysis_result:
        logger.error("Main Assistant Node: Kh√¥ng c√≥ Query Analysis result.")
        error_msg = "L·ªói: Kh√¥ng c√≥ th√¥ng tin ph√¢n t√≠ch ƒë·ªÉ x·ª≠ l√Ω."
        return {
            "messages": [AIMessage(content=error_msg)],
            "final_answer": error_msg,
            "clarification_needed": False
        }

    # Chu·∫©n b·ªã d·ªØ li·ªáu cho prompt h·ªá th·ªëng
    qpa_output_str = query_analysis_result.model_dump_json(indent=2)
    user_roles_str = ", ".join(query_analysis_result.user_roles or ["Employee"])
    asker_role_context = query_analysis_result.asker_role_context or "Employee"
    plan_steps_str = "\n- ".join(query_analysis_result.plan_steps or ["Kh√¥ng c√≥ k·∫ø ho·∫°ch c·ª• th·ªÉ."])
    if query_analysis_result.plan_steps:
        plan_steps_str = "- " + plan_steps_str

    # ƒê·ªãnh d·∫°ng prompt h·ªá th·ªëng
    system_prompt = main_assistant_prompt_str_system.format(
        qpa_output_str=qpa_output_str,
        user_roles_str=user_roles_str,
        asker_role_context=asker_role_context,
        plan_steps_str=plan_steps_str
    )

    # L·∫•y messages t·ª´ state
    all_messages = state.get("messages", [])
    if all_messages and isinstance(all_messages[-1], HumanMessage):
        current_user_input_message = all_messages[-1].content
        chat_history = all_messages[-6:-1]
    else:
        current_user_input_message = query_analysis_result.original_query or state["original_query"]
        chat_history = all_messages

    # Chu·∫©n b·ªã input cho agent
    agent_input = {
        "messages": [
            SystemMessage(content=system_prompt),
            *chat_history,
            HumanMessage(content=current_user_input_message)
        ]
    }

    try:
        # G·ªçi agent executor ƒë·ªÉ x·ª≠ l√Ω input
        response = react_agent_executor.invoke(agent_input)
        print(response)
        #logger.info(f"Main Assistant Node: Ph·∫£n h·ªìi ƒë·∫ßy ƒë·ªß t·ª´ react_agent_executor: {response}")
        # L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ response
        # Tr√≠ch xu·∫•t c√¢u tr·∫£ l·ªùi cu·ªëi c√πng c·ªßa AI t·ª´ response
        final_ai_message_content = "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ Amber."
        if isinstance(response, dict):
            agent_messages = response.get("messages", [])
            if agent_messages and isinstance(agent_messages[-1], AIMessage):
                final_ai_message_content = agent_messages[-1].content
            else:
                logger.warning("Kh√¥ng t√¨m th·∫•y AIMessage cu·ªëi c√πng trong messages c·ªßa response t·ª´ react_agent_executor.")
        else:
            logger.warning(f"Response t·ª´ react_agent_executor kh√¥ng ph·∫£i l√† dict: {type(response)}")

        final_answer = final_ai_message_content

        # Fallback n·∫øu kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi (ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi logic tr√™n)
        if final_answer == "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ Amber." or not final_answer.strip() : # Ki·ªÉm tra k·ªπ h∆°n
            logger.warning("Final answer r·ªóng ho·∫∑c l√† fallback m·∫∑c ƒë·ªãnh. S·ª≠ d·ª•ng fallback t√πy ch·ªânh.")
            final_answer = "·ªêi, Amber t√¨m k·ªπ r·ªìi m√† v·∫´n ch∆∞a th·∫•y th√¥ng tin b·∫°n c·∫ßn üò•. B·∫°n th·ª≠ h·ªèi l·∫°i nh√©!"

        logger.info(f"Main Assistant Node: Ph·∫£n h·ªìi cu·ªëi c√πng ƒë√£ tr√≠ch xu·∫•t: '{final_answer}'")

        # C·∫≠p nh·∫≠t state c·ªßa graph l·ªõn
        # messages c·ªßa graph l·ªõn s·∫Ω l√† messages c≈© + HumanMessage hi·ªán t·∫°i (ƒë√£ c√≥ trong state["messages"])
        # v√† b√¢y gi·ªù th√™m AIMessage t·ª´ agent.
        # C√°ch b·∫°n l√†m `state["messages"] + [AIMessage(content=final_answer)]` l√† ƒê√öNG
        # v√¨ state["messages"] ƒë∆∞·ª£c truy·ªÅn v√†o node n√†y ch·ª©a l·ªãch s·ª≠ cho ƒë·∫øn HumanMessage hi·ªán t·∫°i.
        
        updated_graph_messages = state.get("messages", []) + [AIMessage(content=final_answer)]

        return {
            # "messages": updated_graph_messages, # ƒê√¢y l√† c√°ch c·∫≠p nh·∫≠t messages cho graph L·ªöN
            # Tuy nhi√™n, n·∫øu AmelaReactCompatibleAgentState ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a v·ªõi MessagesPlaceholder,
            # LangGraph s·∫Ω t·ª± ƒë·ªông th√™m AIMessage n√†y v√†o state["messages"] c·ªßa graph l·ªõn
            # n·∫øu node tr·∫£ v·ªÅ AIMessage trong key "messages".
            "messages": [AIMessage(content=final_answer)], # Tr·∫£ v·ªÅ AIMessage ƒë·ªÉ LangGraph t·ª± append
            "final_answer": final_answer, # V·∫´n gi·ªØ ƒë·ªÉ ti·ªán truy c·∫≠p
            "clarification_needed": False
        }

    except Exception as e:
        logger.error(f"L·ªói trong Main Assistant Node: {str(e)}", exc_info=True)
        error_message = f"Xin l·ªói, Amber ƒë√£ g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n: {str(e)[:100]}... üòì"
        # T∆∞∆°ng t·ª±, c·∫≠p nh·∫≠t messages c·ªßa graph l·ªõn v·ªõi l·ªói n√†y
        updated_graph_messages_error = state.get("messages", []) + [AIMessage(content=error_message)]
        return {
            # "messages": updated_graph_messages_error,
            "messages": [AIMessage(content=error_message)],
            "final_answer": error_message,
            "clarification_needed": False
        }
# Placeholder cho node x·ª≠ l√Ω l·ªói (n·∫øu c·∫ßn)
def error_handler_node(state: AmelaReactCompatibleAgentState) -> dict: # S·ª≠a ki·ªÉu tr·∫£ v·ªÅ
    logger.error("--- B·∫Øt ƒë·∫ßu Error Handler Node ---")
    error_message = state.get("error_message", "ƒê√£ c√≥ l·ªói kh√¥ng x√°c ƒë·ªãnh x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i.")
    logger.info(f"Error Handler Node: Th√¥ng b√°o l·ªói: '{error_message}'")
    return {
        "messages": [AIMessage(content=error_message)], # C·∫≠p nh·∫≠t messages
        "final_answer": error_message,
        "clarification_needed": False
    }

def build_graph():
    logger.info("--- B·∫Øt ƒë·∫ßu x√¢y d·ª±ng Graph ---")
    workflow = StateGraph(AmelaReactCompatibleAgentState)

    logger.info("Th√™m c√°c nodes v√†o graph...")
    workflow.add_node("query_analyzer", query_analysis_node)
    workflow.add_node("direct_responder", direct_response_node)
    workflow.add_node("clarification_generator", clarification_node)
    workflow.add_node("main_assistant", main_assistant_node)
    workflow.add_node("error_handler", error_handler_node)

    workflow.set_entry_point("query_analyzer")
    logger.info("ƒê·∫∑t entry point l√† 'query_analyzer'.")

    # S·ª≠a l·ªói TypeError: start_key kh√¥ng c√≤n ƒë∆∞·ª£c s·ª≠ d·ª•ng
    workflow.add_conditional_edges(
        "query_analyzer",           # Node ngu·ªìn
        route_after_qpa,            # H√†m ƒëi·ªÅu ki·ªán (router)
        {                           # Mapping
            "direct_response_node": "direct_responder",
            "clarification_node": "clarification_generator",
            "main_assistant_node": "main_assistant",
            "error_handler": "error_handler"
        }
    )
    logger.info("Th√™m conditional edges t·ª´ 'query_analyzer' d·ª±a tr√™n 'route_after_qpa'.")

    workflow.add_edge("direct_responder", END)
    workflow.add_edge("clarification_generator", END)
    workflow.add_edge("main_assistant", END)
    workflow.add_edge("error_handler", END)
    logger.info("Th√™m edges ƒë·∫øn END cho 'direct_responder', 'clarification_generator', 'main_assistant', 'error_handler'.")

    # memory = SqliteSaver.from_conn_string(":memory:")
    # L∆∞u v√†o file ƒë·ªÉ c√≥ th·ªÉ ki·ªÉm tra session state sau n√†y n·∫øu c·∫ßn
    checkpointer = InMemorySaver() # S·ª¨ D·ª§NG IN MEMORY SAVER
    logger.info("S·ª≠ d·ª•ng InMemorySaver ƒë·ªÉ test.")

    app = workflow.compile(checkpointer=checkpointer)
    # Show workflow
    #display(Image(app.get_graph().draw_mermaid_png()))
    logger.info("--- Graph ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch th√†nh c√¥ng (v·ªõi InMemorySaver) ---")
    return app

# Ch·∫°y graph
if __name__ == "__main__":
    logger.info("--- B·∫Øt ƒë·∫ßu ch·∫°y graph ---")
    app = build_graph()
    # Ch·∫°y graph v·ªõi m·ªôt state m·∫´u
    config={"configurable": {"thread_id": "test_thread_id"}}
    sample_state = {
        "original_query": "T√¨m hi·ªÉu v·ªÅ quy tr√¨nh quy·∫øt to√°n thu·∫ø TNCN t·∫°i Amela.",
        "user_roles": ["nh√¢n vi√™n", "qu·∫£n l√Ω"],
        "messages": [
            HumanMessage(content="Ch√†o Amber, t√¥i mu·ªën bi·∫øt v·ªÅ quy tr√¨nh quy·∫øt to√°n thu·∫ø TNCN."),
            AIMessage(content="Ch√†o b·∫°n! T√¥i l√† Amber, tr·ª£ l√Ω ·∫£o Amela. B·∫°n c·∫ßn t√¨m hi·ªÉu g√¨ v·ªÅ quy tr√¨nh n√†y?")
        ]
    }
    result = app.invoke(sample_state, config=config)
    print(result)