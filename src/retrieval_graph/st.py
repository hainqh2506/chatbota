# app_streamlit.py
import streamlit as st
# import asyncio # Kh√¥ng c·∫ßn thi·∫øt n·∫øu d√πng invoke() ƒë·ªìng b·ªô ho√†n to√†n
import logging
import uuid

try:
    from state import AmelaReactCompatibleAgentState
    from graph_builder import build_graph # Gi·∫£ s·ª≠ n√≥ tr·∫£ v·ªÅ app c√≥ invoke()
    from langchain_core.messages import HumanMessage, AIMessage
except ImportError as e:
    st.error(f"L·ªói import: {e}. ƒê·∫£m b·∫£o c√°c file c·ªßa project ƒë∆∞·ª£c ƒë·∫∑t ƒë√∫ng ch·ªó.")
    st.stop()

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', force=True)
logger = logging.getLogger(__name__)

@st.cache_resource
def load_graph_app():
    logger.info("B·∫Øt ƒë·∫ßu kh·ªüi t·∫°o graph cho Streamlit app...")
    try:
        app = build_graph() # build_graph() tr·∫£ v·ªÅ compiled_app
        logger.info("Graph ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng cho Streamlit.")
        # Ki·ªÉm tra xem app c√≥ ph∆∞∆°ng th·ª©c invoke kh√¥ng
        if not hasattr(app, 'invoke'):
            logger.error("ƒê·ªëi t∆∞·ª£ng graph ƒë∆∞·ª£c bi√™n d·ªãch kh√¥ng c√≥ ph∆∞∆°ng th·ª©c 'invoke'.")
            st.error("L·ªói c·∫•u h√¨nh: Graph kh√¥ng h·ªó tr·ª£ g·ªçi ƒë·ªìng b·ªô (invoke).")
            return None
        return app
    except Exception as e:
        logger.error(f"L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o graph: {e}", exc_info=True)
        st.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o chatbot: {e}")
        return None

graph_app = load_graph_app()

def get_response_from_graph():
    pass
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
    logger.info(f"T·∫°o session Streamlit m·ªõi v·ªõi ID: {st.session_state.session_id}")

if "messages_ui" not in st.session_state:
    st.session_state.messages_ui = []

if "langgraph_messages" not in st.session_state:
    st.session_state.langgraph_messages = [] # ƒê√¢y l√† l·ªãch s·ª≠ cho LangGraph

if "user_roles" not in st.session_state:
    st.session_state.user_roles = ["staff"]

st.title("üí¨ Amber - RAG Chatbot N·ªôi b·ªô (ƒê·ªìng b·ªô)")
st.caption(f"Session ID: {st.session_state.session_id}")

with st.sidebar:
    st.header("C·∫•u h√¨nh ng∆∞·ªùi d√πng")
    selected_roles = st.multiselect(
        "Ch·ªçn vai tr√≤ c·ªßa b·∫°n:",
        options=["staff", "manager", "developer", "newbie", "guest"],
        default=st.session_state.user_roles
    )
    if selected_roles != st.session_state.user_roles:
        st.session_state.user_roles = selected_roles
        st.rerun()
    st.info(f"ƒêang ch·∫°y v·ªõi vai tr√≤: {', '.join(st.session_state.user_roles)}")

for msg_ui in st.session_state.messages_ui:
    with st.chat_message(msg_ui["role"]):
        st.markdown(msg_ui["content"])

if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
    if not graph_app:
        st.error("Chatbot ch∆∞a s·∫µn s√†ng do l·ªói kh·ªüi t·∫°o graph.")
        st.stop()

    st.session_state.messages_ui.append({"role": "user", "content": prompt})
    st.session_state.langgraph_messages.append(HumanMessage(content=prompt))

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        thinking_message = "Amber ƒëang suy nghƒ©... ü§î"
        message_placeholder.markdown(thinking_message)

        try:
            graph_input = {
                "messages": st.session_state.langgraph_messages, # Truy·ªÅn to√†n b·ªô l·ªãch s·ª≠ hi·ªán t·∫°i
                "original_query": prompt,
                "user_id": st.session_state.session_id,
                "user_roles": st.session_state.user_roles,
            }
            
            logger.info(f"G·ªçi graph.invoke() v·ªõi input cho thread_id '{st.session_state.session_id}': "
                        f"Query='{prompt}', Roles={st.session_state.user_roles}, "
                        f"Num LangGraph Msgs={len(st.session_state.langgraph_messages)}")

            # G·ªçi phi√™n b·∫£n ƒë·ªìng b·ªô c·ªßa graph
            final_graph_state = graph_app.invoke(
                graph_input, 
                config={"configurable": {"thread_id": st.session_state.session_id}}
            )
            # X·ª≠ l√Ω k·∫øt qu·∫£
            if final_graph_state and final_graph_state.get("messages"):
                ai_message_obj = final_graph_state["messages"][-1]
                if isinstance(ai_message_obj, AIMessage):
                    full_response = ai_message_obj.content
                    st.session_state.langgraph_messages = final_graph_state["messages"] # C·∫≠p nh·∫≠t l·ªãch s·ª≠ ƒë·∫ßy ƒë·ªß
                else:
                    full_response = "L·ªói: Ph·∫£n h·ªìi kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng AIMessage."
                    logger.error(f"Ph·∫£n h·ªìi t·ª´ graph kh√¥ng ph·∫£i AIMessage: {ai_message_obj}")
            elif final_graph_state: # C√≥ state cu·ªëi nh∆∞ng kh√¥ng c√≥ messages h·ª£p l·ªá
                 full_response = "L·ªói: State cu·ªëi t·ª´ graph kh√¥ng ch·ª©a AIMessage h·ª£p l·ªá."
                 logger.error(f"State cu·ªëi kh√¥ng h·ª£p l·ªá: {final_graph_state}")
            else: # Kh√¥ng c√≥ state cu·ªëi n√†o ƒë∆∞·ª£c tr·∫£ v·ªÅ
                full_response = "Xin l·ªói, Amber kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n l√∫c n√†y (kh√¥ng c√≥ state cu·ªëi)."
                logger.error(f"Kh√¥ng nh·∫≠n ƒë∆∞·ª£c state cu·ªëi t·ª´ graph.invoke: {final_graph_state}")


            message_placeholder.markdown(full_response)
            st.session_state.messages_ui.append({"role": "assistant", "content": full_response})

        except Exception as e:
            logger.error(f"L·ªói khi g·ªçi graph.invoke(): {e}", exc_info=True)
            error_msg = f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}"
            message_placeholder.error(error_msg)
            st.session_state.messages_ui.append({"role": "assistant", "content": error_msg}) 